# ALMA-ADVISOR

Plateforme de conseil en transformation digitale avec ingestion documentaire et g√©n√©ration automatique de rapports RAG.

## Fonctionnalit√©s

- üìä **Tableau de bord** - Vue d'ensemble des projets
- üìù **Cr√©ation de projets** - Assistant en 4 √©tapes
- üìÑ **Upload de documents** - Support PDF, DOCX, XLSX, CSV, TXT, MD
- üß† **Pipeline RAG** - Ingestion ‚Üí Analyse ‚Üí G√©n√©ration
- üìà **G√©n√©ration automatique** - Rapports, diagrammes, tableaux
- üé® **Diagrammes** - C4, BPMN, Gantt, STRIDE
- üìã **Tableaux** - RICE, Budget, RACI, BSC
- üì§ **Export** - PDF + annexes

## Configuration

### 1. Variables d'environnement

Cr√©ez un fichier `.env.local` avec :

```env
# Database
DATABASE_URL="postgresql://username:password@localhost:5432/alma_advisor"

# OpenAI API (for embeddings and LLM)
OPENAI_API_KEY="your_openai_api_key_here"

# Alternative LLM Providers (optional)
ANTHROPIC_API_KEY="your_anthropic_api_key_here"
GROQ_API_KEY="your_groq_api_key_here"

# LLM Provider (openai, anthropic, groq)
LLM_PROVIDER="openai"

# File Upload Settings
UPLOAD_DIR="./uploads"
MAX_FILE_SIZE="50000000"
```

### 2. Base de donn√©es

```bash
# Installer les d√©pendances
npm install

# G√©n√©rer le client Prisma
npm run db:generate

# Pousser le sch√©ma vers la base de donn√©es
npm run db:push
```

### 3. D√©veloppement

```bash
# D√©marrer le serveur de d√©veloppement
npm run dev
```

## D√©ploiement sur Vercel

### 1. Pr√©paration

1. Cr√©ez un compte Vercel
2. Connectez votre repository GitHub
3. Configurez une base de donn√©es PostgreSQL (Vercel Postgres, Supabase, ou PlanetScale)

### 2. Variables d'environnement sur Vercel

Dans les param√®tres du projet Vercel, ajoutez :

- `DATABASE_URL` - URL de votre base de donn√©es PostgreSQL
- `OPENAI_API_KEY` - Cl√© API OpenAI
- `LLM_PROVIDER` - "openai" (ou autre fournisseur)
- `UPLOAD_DIR` - "./uploads"
- `MAX_FILE_SIZE` - "50000000"

### 3. D√©ploiement

```bash
# Le d√©ploiement se fait automatiquement via Git
git add .
git commit -m "Deploy to Vercel"
git push origin main
```

## Architecture

### Backend API Routes

- `POST /api/projects` - Cr√©er un projet
- `GET /api/projects` - Lister les projets
- `GET /api/projects/[id]` - D√©tails d'un projet
- `POST /api/projects/[id]/upload` - Upload de documents
- `POST /api/projects/[id]/ingest` - Ingestion des documents
- `POST /api/projects/[id]/embed` - G√©n√©ration des embeddings
- `POST /api/projects/[id]/generate` - G√©n√©ration du rapport

### Pipeline RAG

1. **Upload** - Documents stock√©s et m√©tadonn√©es enregistr√©es
2. **Ingestion** - Parsing et chunking des documents
3. **Embeddings** - G√©n√©ration des vecteurs s√©mantiques
4. **G√©n√©ration** - Cr√©ation du rapport avec RAG

### Technologies

- **Frontend** - Next.js 14, React, TypeScript, Tailwind CSS
- **Backend** - Next.js API Routes, Prisma ORM
- **Base de donn√©es** - PostgreSQL
- **IA** - OpenAI API (embeddings + LLM)
- **UI** - Radix UI, Lucide Icons
- **D√©ploiement** - Vercel

## D√©ploiement Rapide sur Vercel

### 1. Clonez et pr√©parez le projet
```bash
git clone <votre-repo>
cd alma-advisor
npm install
```

### 2. Configurez les variables d'environnement
Cr√©ez un fichier `.env.local` :
```env
DATABASE_URL="postgresql://username:password@localhost:5432/alma_advisor"
OPENAI_API_KEY="your_openai_api_key_here"
LLM_PROVIDER="openai"
```

### 3. Initialisez la base de donn√©es
```bash
npx prisma db push
```

### 4. D√©ployez sur Vercel
```bash
# Connectez votre repo √† GitHub
git remote add origin https://github.com/VOTRE_USERNAME/alma-advisor.git
git push -u origin main

# D√©ployez sur Vercel via l'interface web
# https://vercel.com/new
```

### 5. Configurez les variables d'environnement sur Vercel
Dans les param√®tres du projet Vercel, ajoutez :
- `DATABASE_URL` - URL de votre base PostgreSQL
- `OPENAI_API_KEY` - Votre cl√© API OpenAI
- `LLM_PROVIDER` - "openai"

## Documentation Compl√®te

- [Guide de D√©ploiement D√©taill√©](./DEPLOY.md)
- [Architecture Technique](./README.md#architecture)

## Support

Pour toute question ou probl√®me :
1. Consultez le guide [DEPLOY.md](./DEPLOY.md)
2. V√©rifiez les logs Vercel
3. Contactez l'√©quipe de d√©veloppement
